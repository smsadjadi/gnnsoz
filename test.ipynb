{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(raw_data):\n",
    "    \"\"\"\n",
    "    Preprocess raw multimodal data.\n",
    "    In practice, you would include steps such as:\n",
    "      - Artifact removal and filtering\n",
    "      - Signal normalization and alignment\n",
    "      - Extraction of time series from regions of interest (ROIs)\n",
    "    \"\"\"\n",
    "    # For demonstration, we assume raw_data is already a NumPy array\n",
    "    processed_data = raw_data  # Replace with your actual processing pipeline\n",
    "    return processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_graph(processed_data, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Construct a connectivity graph from the processed data.\n",
    "    \n",
    "    Parameters:\n",
    "      processed_data: 2D NumPy array where each row is the time series of a ROI.\n",
    "      threshold: Correlation threshold to determine the presence of an edge.\n",
    "      \n",
    "    Returns:\n",
    "      G: A NetworkX graph.\n",
    "      connectivity_matrix: The connectivity matrix computed as correlations.\n",
    "    \"\"\"\n",
    "    # Compute the Pearson correlation matrix as a proxy for connectivity\n",
    "    connectivity_matrix = np.corrcoef(processed_data)\n",
    "    \n",
    "    # Optionally threshold the matrix to retain only stronger connections\n",
    "    adjacency_matrix = (np.abs(connectivity_matrix) >= threshold).astype(float)\n",
    "    np.fill_diagonal(adjacency_matrix, 0)\n",
    "    \n",
    "    # Construct an undirected graph from the adjacency matrix\n",
    "    G = nx.from_numpy_array(adjacency_matrix)\n",
    "    return G, adjacency_matrix\n",
    "\n",
    "def compute_graph_metrics(G):\n",
    "    \"\"\"\n",
    "    Compute relevant graph metrics that will be used as features.\n",
    "    \n",
    "    Returns a dictionary of metrics (e.g. local clustering coefficient and efficiency).\n",
    "    \"\"\"\n",
    "    clustering = nx.clustering(G)  # Local clustering coefficient per node\n",
    "    global_eff = nx.global_efficiency(G)  # Global efficiency of the graph\n",
    "    \n",
    "    metrics = {\n",
    "        'clustering': clustering,\n",
    "        'global_efficiency': global_eff\n",
    "    }\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCNLayer(nn.Module):\n",
    "    def __init__(self, in_features, out_features):\n",
    "        \"\"\"\n",
    "        A single GCN layer implementing:\n",
    "          H_out = σ( A_norm * H_in * W )\n",
    "        where A_norm is the symmetric normalized adjacency matrix.\n",
    "        \"\"\"\n",
    "        super(GCNLayer, self).__init__()\n",
    "        self.linear = nn.Linear(in_features, out_features)\n",
    "        \n",
    "    def forward(self, H, A_norm):\n",
    "        H = torch.mm(A_norm, H)\n",
    "        H = self.linear(H)\n",
    "        return F.relu(H)\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features, num_classes):\n",
    "        \"\"\"\n",
    "        A simple 2-layer GCN for node classification.\n",
    "        \"\"\"\n",
    "        super(GCN, self).__init__()\n",
    "        self.gcn1 = GCNLayer(in_features, hidden_features)\n",
    "        self.gcn2 = GCNLayer(hidden_features, num_classes)\n",
    "        \n",
    "    def forward(self, H, A_norm):\n",
    "        H = self.gcn1(H, A_norm)\n",
    "        H = self.gcn2(H, A_norm)\n",
    "        return H\n",
    "\n",
    "def normalize_adjacency(adjacency_matrix):\n",
    "    \"\"\"\n",
    "    Compute the symmetric normalized adjacency matrix:\n",
    "      A_norm = D^(-1/2) (A + I) D^(-1/2)\n",
    "    \"\"\"\n",
    "    A = adjacency_matrix + np.eye(adjacency_matrix.shape[0])\n",
    "    D = np.diag(np.sum(A, axis=1))\n",
    "    D_inv_sqrt = np.linalg.inv(np.sqrt(D))\n",
    "    A_norm = np.matmul(np.matmul(D_inv_sqrt, A), D_inv_sqrt)\n",
    "    return torch.from_numpy(A_norm).float()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(outputs, labels, class_weights, lateralization_term=0.0):\n",
    "    \"\"\"\n",
    "    Compute the total loss as a sum of weighted cross entropy\n",
    "    and an additional lateralization penalty.\n",
    "    \n",
    "    Parameters:\n",
    "      outputs: Model predictions (logits).\n",
    "      labels: True class labels.\n",
    "      class_weights: Tensor of weights for each class.\n",
    "      lateralization_term: Additional penalty term (e.g., enforcing symmetry).\n",
    "    \n",
    "    Returns:\n",
    "      loss: Combined loss.\n",
    "    \"\"\"\n",
    "    criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "    loss_ce = criterion(outputs, labels)\n",
    "    loss = loss_ce + lateralization_term\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, A_norm, features, labels, num_epochs=100, class_weights=torch.tensor([1.0, 1.0])):\n",
    "    \"\"\"\n",
    "    Train the GCN model.\n",
    "    \n",
    "    Parameters:\n",
    "      model: An instance of the GCN model.\n",
    "      optimizer: Optimizer (e.g., Adam).\n",
    "      A_norm: Normalized adjacency matrix (tensor).\n",
    "      features: Node feature matrix (tensor).\n",
    "      labels: True labels for each node (tensor).\n",
    "      num_epochs: Number of training epochs.\n",
    "      class_weights: Class weighting tensor for handling imbalance.\n",
    "      \n",
    "    Returns:\n",
    "      model: Trained model.\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(features, A_norm)\n",
    "        \n",
    "        # Here, lateralization_term is set to 0.0 as a placeholder.\n",
    "        # Replace with your computed lateralization penalty if available.\n",
    "        lateralization_term = 0.0\n",
    "        loss = compute_loss(outputs, labels, class_weights, lateralization_term)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}: Loss = {loss.item():.4f}\")\n",
    "    return model\n",
    "\n",
    "def evaluate_model(model, A_norm, features, labels):\n",
    "    \"\"\"\n",
    "    Evaluate the trained model and compute accuracy.\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(features, A_norm)\n",
    "        predictions = outputs.argmax(dim=1)\n",
    "        accuracy = (predictions == labels).float().mean().item()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Example: Assume raw_data is loaded as a NumPy array (rows: ROIs, columns: time points)\n",
    "    # For demonstration purposes, we create synthetic data.\n",
    "    num_rois = 50  # number of brain regions (nodes)\n",
    "    time_points = 120  # number of time points per region\n",
    "    raw_data = np.random.rand(num_rois, time_points)\n",
    "    \n",
    "    # 1. Preprocess Data\n",
    "    processed_data = preprocess_data(raw_data)\n",
    "    \n",
    "    # 2. Construct Graph\n",
    "    G, connectivity_matrix = construct_graph(processed_data, threshold=0.6)\n",
    "    metrics = compute_graph_metrics(G)\n",
    "    print(\"Graph Metrics:\", metrics)\n",
    "    \n",
    "    # 3. Prepare Graph Neural Network inputs\n",
    "    A_norm = normalize_adjacency(connectivity_matrix)\n",
    "    \n",
    "    # Create dummy node features (for example, using the processed data’s statistics)\n",
    "    # Here we use the mean of each ROI time series as a feature.\n",
    "    features_np = np.mean(processed_data, axis=1, keepdims=True)\n",
    "    features = torch.from_numpy(features_np).float()\n",
    "    \n",
    "    # Dummy labels for each node (for example, two classes: epileptic focus vs. non-focus)\n",
    "    labels = torch.randint(0, 2, (num_rois,))\n",
    "    \n",
    "    # 4. Instantiate GCN Model\n",
    "    in_features = features.shape[1]\n",
    "    hidden_features = 16\n",
    "    num_classes = 2\n",
    "    model = GCN(in_features, hidden_features, num_classes)\n",
    "    \n",
    "    # 5. Set up optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    \n",
    "    # 6. Train the Model\n",
    "    model = train_model(model, optimizer, A_norm, features, labels, num_epochs=50)\n",
    "    \n",
    "    # 7. Evaluate the Model\n",
    "    acc = evaluate_model(model, A_norm, features, labels)\n",
    "    print(f\"Model Accuracy: {acc*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neuroimaging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
